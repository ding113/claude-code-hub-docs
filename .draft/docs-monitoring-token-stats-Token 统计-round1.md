# Token 统计 (Token Statistics) - Round 1 Exploration Draft

## Intent Analysis

The Token Statistics documentation aims to provide a comprehensive technical reference for understanding how claude-code-hub tracks, aggregates, and utilizes token usage data across the entire request lifecycle. This feature is fundamental to:

1. **Cost Calculation**: Accurate token counting is the foundation of cost calculation and billing
2. **Rate Limiting**: Token-based quotas help prevent abuse and manage resource allocation
3. **Monitoring & Analytics**: Token statistics provide insights into usage patterns and system health
4. **Multi-Provider Support**: Normalizing token data from different AI providers (Claude, OpenAI, Gemini, Codex)

The documentation should serve both operators who need to understand system behavior and developers who need to integrate with or extend the token tracking system.

## Behavior Summary

### Token Types Tracked

The system tracks multiple categories of tokens to support accurate billing and analytics:

1. **Input Tokens**: Tokens sent to the model in the request (prompt)
2. **Output Tokens**: Tokens generated by the model in the response (completion)
3. **Cache Creation Tokens**: Tokens written to prompt cache (5m or 1h TTL variants)
4. **Cache Read Tokens**: Tokens read from existing prompt cache
5. **Image Tokens**: Special modality tokens for image input/output (Gemini support)

### Token Flow Overview

```
Request → Proxy Handler → Provider API → Response → Usage Extraction → 
Database Storage → Aggregation → Rate Limit Check → Cost Calculation
```

### Key Behaviors

1. **Provider-Specific Normalization**: Different providers return usage in different formats; the system normalizes all to a common schema
2. **Streaming Response Handling**: Token usage is extracted from SSE streams in real-time
3. **Dual Storage**: Token data is stored both in PostgreSQL for persistence and Redis for real-time rate limiting
4. **Async Write Buffer**: Token updates use a write buffer to optimize database performance
5. **Session Aggregation**: Tokens are aggregated at the session level for monitoring

## Config/Commands

### Database Schema

Token statistics are stored in the `message_request` table defined in `/Users/ding/Github/claude-code-hub/src/drizzle/schema.ts`:

```typescript
// Message Request table - Token-related fields
export const messageRequest = pgTable('message_request', {
  id: serial('id').primaryKey(),
  providerId: integer('provider_id').notNull(),
  userId: integer('user_id').notNull(),
  key: varchar('key').notNull(),
  model: varchar('model', { length: 128 }),
  
  // Token 使用信息
  inputTokens: bigint('input_tokens', { mode: 'number' }),
  outputTokens: bigint('output_tokens', { mode: 'number' }),
  cacheCreationInputTokens: bigint('cache_creation_input_tokens', { mode: 'number' }),
  cacheReadInputTokens: bigint('cache_read_input_tokens', { mode: 'number' }),
  cacheCreation5mInputTokens: bigint('cache_creation_5m_input_tokens', { mode: 'number' }),
  cacheCreation1hInputTokens: bigint('cache_creation_1h_input_tokens', { mode: 'number' }),
  cacheTtlApplied: varchar('cache_ttl_applied', { length: 10 }),
  
  // 1M Context Window 应用状态
  context1mApplied: boolean('context_1m_applied').default(false),
  
  createdAt: timestamp('created_at', { withTimezone: true }).defaultNow(),
  updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow(),
  deletedAt: timestamp('deleted_at', { withTimezone: true }),
}, (table) => ({
  // 优化统计查询的复合索引（用户+时间+费用）
  messageRequestUserDateCostIdx: index('idx_message_request_user_date_cost')
    .on(table.userId, table.createdAt, table.costUsd)
    .where(sql`${table.deletedAt} IS NULL`),
  // Session 查询索引（按 session 聚合查看对话）
  messageRequestSessionIdIdx: index('idx_message_request_session_id')
    .on(table.sessionId)
    .where(sql`${table.deletedAt} IS NULL`),
}));
```

### UsageMetrics Type Definition

Located in `/Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts`:

```typescript
export type UsageMetrics = {
  input_tokens?: number;
  output_tokens?: number;
  cache_creation_input_tokens?: number;
  cache_creation_5m_input_tokens?: number;
  cache_creation_1h_input_tokens?: number;
  cache_ttl?: "5m" | "1h" | "mixed";
  cache_read_input_tokens?: number;
  // 图片 modality tokens（从 candidatesTokensDetails/promptTokensDetails 提取）
  input_image_tokens?: number;
  output_image_tokens?: number;
};
```

### Environment Configuration

Token-related configuration is controlled through environment variables (defined in `/Users/ding/Github/claude-code-hub/src/lib/config/env.schema.ts`):

- `MESSAGE_REQUEST_WRITE_MODE`: Controls whether token updates use async buffer ("async") or direct writes ("sync")

## Edge Cases

### 1. Provider Format Variations

Different providers return token usage in different formats:

**Claude Format**:
```json
{
  "usage": {
    "input_tokens": 1000,
    "output_tokens": 500,
    "cache_creation_input_tokens": 200,
    "cache_read_input_tokens": 100
  }
}
```

**OpenAI Format**:
```json
{
  "usage": {
    "prompt_tokens": 1000,
    "completion_tokens": 500,
    "input_tokens_details": {
      "cached_tokens": 100
    }
  }
}
```

**Gemini Format**:
```json
{
  "usageMetadata": {
    "promptTokenCount": 1000,
    "candidatesTokenCount": 500,
    "cachedContentTokenCount": 100
  }
}
```

The system handles these variations in the `extractUsageMetrics` function.

### 2. Gemini Token Deduction

Gemini's `promptTokenCount` includes cached tokens, which would cause double-counting. The system automatically deducts cached tokens:

```typescript
// From /Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts
if (typeof usage.promptTokenCount === "number") {
  const cachedTokens =
    typeof usage.cachedContentTokenCount === "number" ? usage.cachedContentTokenCount : 0;
  result.input_tokens = Math.max(usage.promptTokenCount - cachedTokens, 0);
  hasAny = true;
}
```

### 3. Codex Cache Token Adjustment

Codex includes cached tokens in input_tokens, requiring adjustment:

```typescript
// From /Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts
function adjustUsageForProviderType(
  usage: UsageMetrics,
  providerType: string | null | undefined
): UsageMetrics {
  if (providerType !== "codex") {
    return usage;
  }

  const cachedTokens = usage.cache_read_input_tokens;
  const inputTokens = usage.input_tokens;

  if (typeof cachedTokens !== "number" || typeof inputTokens !== "number") {
    return usage;
  }

  const adjustedInput = Math.max(inputTokens - cachedTokens, 0);
  
  return {
    ...usage,
    input_tokens: adjustedInput,
  };
}
```

### 4. Cache TTL Derivation

When providers don't explicitly specify cache TTL, the system derives it from available data:

```typescript
// From /Users/ding/Github/claude-code-hub/src/lib/utils/cost-calculation.ts
let cache5mTokens = usage.cache_creation_5m_input_tokens;
let cache1hTokens = usage.cache_creation_1h_input_tokens;

if (typeof usage.cache_creation_input_tokens === "number") {
  const remaining =
    usage.cache_creation_input_tokens - (cache5mTokens ?? 0) - (cache1hTokens ?? 0);

  if (remaining > 0) {
    const target = usage.cache_ttl === "1h" ? "1h" : "5m";
    if (target === "1h") {
      cache1hTokens = (cache1hTokens ?? 0) + remaining;
    } else {
      cache5mTokens = (cache5mTokens ?? 0) + remaining;
    }
  }
}
```

### 5. Missing Token Data

When providers don't return usage data (e.g., during errors or certain streaming scenarios), the system gracefully handles missing data by:
- Returning `null` from `extractUsageMetrics`
- Skipping cost calculation
- Still recording the request for analytics

### 6. Token Counting Endpoint

The `/v1/messages/count_tokens` endpoint is special-cased to skip rate limiting and concurrent session tracking:

```typescript
// From /Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/session.ts
isCountTokensRequest(): boolean {
  const endpoint = this.getEndpoint();
  return endpoint === "/v1/messages/count_tokens";
}
```

## References

### Core Token Extraction Logic

**File**: `/Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts`

The `extractUsageMetrics` function is the central hub for normalizing token data from all providers:

```typescript
function extractUsageMetrics(value: unknown): UsageMetrics | null {
  if (!value || typeof value !== "object") {
    return null;
  }

  const usage = value as Record<string, unknown>;
  const result: UsageMetrics = {};
  let hasAny = false;

  // Standard input_tokens
  if (typeof usage.input_tokens === "number") {
    result.input_tokens = usage.input_tokens;
    hasAny = true;
  }

  // Gemini support with token deduction
  if (typeof usage.promptTokenCount === "number") {
    const cachedTokens =
      typeof usage.cachedContentTokenCount === "number" ? usage.cachedContentTokenCount : 0;
    result.input_tokens = Math.max(usage.promptTokenCount - cachedTokens, 0);
    hasAny = true;
  }

  // Output tokens
  if (typeof usage.candidatesTokenCount === "number") {
    result.output_tokens = usage.candidatesTokenCount;
    hasAny = true;
  }
  if (typeof usage.output_tokens === "number") {
    result.output_tokens = usage.output_tokens;
    hasAny = true;
  }

  // Gemini thinking tokens (added to output)
  if (typeof usage.thoughtsTokenCount === "number" && usage.thoughtsTokenCount > 0) {
    result.output_tokens = (result.output_tokens ?? 0) + usage.thoughtsTokenCount;
    hasAny = true;
  }

  // Cache tokens handling
  if (typeof usage.cache_creation_input_tokens === "number") {
    result.cache_creation_input_tokens = usage.cache_creation_input_tokens;
    hasAny = true;
  }

  // Cache creation with TTL breakdown
  const cacheCreationDetails = usage.cache_creation as Record<string, unknown> | undefined;
  if (cacheCreationDetails) {
    if (typeof cacheCreationDetails.ephemeral_5m_input_tokens === "number") {
      result.cache_creation_5m_input_tokens = cacheCreationDetails.ephemeral_5m_input_tokens;
      hasAny = true;
    }
    if (typeof cacheCreationDetails.ephemeral_1h_input_tokens === "number") {
      result.cache_creation_1h_input_tokens = cacheCreationDetails.ephemeral_1h_input_tokens;
      hasAny = true;
    }
  }

  // Cache read tokens
  if (typeof usage.cache_read_input_tokens === "number") {
    result.cache_read_input_tokens = usage.cache_read_input_tokens;
    hasAny = true;
  }

  // OpenAI Response API format
  if (!result.cache_read_input_tokens) {
    const inputTokensDetails = usage.input_tokens_details as Record<string, unknown> | undefined;
    if (inputTokensDetails && typeof inputTokensDetails.cached_tokens === "number") {
      result.cache_read_input_tokens = inputTokensDetails.cached_tokens;
      hasAny = true;
    }
  }

  return hasAny ? result : null;
}
```

### Token Usage Parsing from Response

**File**: `/Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts`

The `parseUsageFromResponseText` function handles both streaming and non-streaming responses:

```typescript
export function parseUsageFromResponseText(
  responseText: string,
  providerType: string | null | undefined
): {
  usageRecord: Record<string, unknown> | null;
  usageMetrics: UsageMetrics | null;
} {
  let usageRecord: Record<string, unknown> | null = null;
  let usageMetrics: UsageMetrics | null = null;

  const applyUsageValue = (value: unknown, source: string) => {
    if (usageMetrics) {
      return;
    }

    if (!value || typeof value !== "object") {
      return;
    }

    const extracted = extractUsageMetrics(value);
    if (!extracted) {
      return;
    }

    usageRecord = value as Record<string, unknown>;
    usageMetrics = adjustUsageForProviderType(extracted, providerType);

    logger.debug("[ResponseHandler] Parsed usage from response", {
      source,
      providerType,
      usage: usageMetrics,
    });
  };

  try {
    const parsedValue = JSON.parse(responseText);

    if (parsedValue && typeof parsedValue === "object" && !Array.isArray(parsedValue)) {
      const parsed = parsedValue as Record<string, unknown>;

      // Standard usage fields
      if (parsed.usage) {
        applyUsageValue(parsed.usage, "json.usage");
      }
    }
  } catch {
    // Not valid JSON, might be SSE stream
  }

  // Handle SSE streaming format (Claude)
  if (!usageMetrics && responseText.includes("event:")) {
    const events = parseSSEData(responseText);
    let messageStartUsage: UsageMetrics | null = null;
    let messageDeltaUsage: UsageMetrics | null = null;

    for (const event of events) {
      if (event.event === "message_start") {
        let usageValue: unknown = null;
        if (data.message && typeof data.message === "object") {
          const messageObj = data.message as Record<string, unknown>;
          usageValue = messageObj.usage;
        }
        if (!usageValue) {
          usageValue = data.usage;
        }

        if (usageValue && typeof usageValue === "object") {
          const extracted = extractUsageMetrics(usageValue);
          if (extracted) {
            messageStartUsage = mergeUsageMetrics(messageStartUsage, extracted);
          }
        }
      }

      if (event.event === "message_delta") {
        let usageValue: unknown = data.usage;
        if (!usageValue && data.delta && typeof data.delta === "object") {
          usageValue = (data.delta as Record<string, unknown>).usage;
        }

        if (usageValue && typeof usageValue === "object") {
          const extracted = extractUsageMetrics(usageValue);
          if (extracted) {
            messageDeltaUsage = mergeUsageMetrics(messageDeltaUsage, extracted);
          }
        }
      }
    }

    // Claude SSE merge rule: prefer message_delta, fallback to message_start for missing fields
    const mergedClaudeUsage = (() => {
      if (messageDeltaUsage && messageStartUsage) {
        return mergeUsageMetrics(messageStartUsage, messageDeltaUsage);
      }
      return messageDeltaUsage ?? messageStartUsage;
    })();

    if (mergedClaudeUsage) {
      usageMetrics = adjustUsageForProviderType(mergedClaudeUsage, providerType);
      usageRecord = mergedClaudeUsage as unknown as Record<string, unknown>;
    }
  }

  return { usageRecord, usageMetrics };
}
```

### Cost Calculation

**File**: `/Users/ding/Github/claude-code-hub/src/lib/utils/cost-calculation.ts`

The cost calculation function handles tiered pricing for different token types:

```typescript
export function calculateRequestCost(
  usage: UsageMetrics,
  priceData: ModelPriceData,
  multiplier: number = 1.0,
  context1mApplied: boolean = false
): Decimal {
  const segments: Decimal[] = [];

  const inputCostPerToken = priceData.input_cost_per_token;
  const outputCostPerToken = priceData.output_cost_per_token;

  // Derive cache creation tokens by TTL
  let cache5mTokens = usage.cache_creation_5m_input_tokens;
  let cache1hTokens = usage.cache_creation_1h_input_tokens;

  if (typeof usage.cache_creation_input_tokens === "number") {
    const remaining =
      usage.cache_creation_input_tokens - (cache5mTokens ?? 0) - (cache1hTokens ?? 0);

    if (remaining > 0) {
      const target = usage.cache_ttl === "1h" ? "1h" : "5m";
      if (target === "1h") {
        cache1hTokens = (cache1hTokens ?? 0) + remaining;
      } else {
        cache5mTokens = (cache5mTokens ?? 0) + remaining;
      }
    }
  }

  // Check for 200K tiered pricing (Gemini models)
  const inputAbove200k = priceData.input_cost_per_token_above_200k_tokens;
  const outputAbove200k = priceData.output_cost_per_token_above_200k_tokens;

  // Calculate input cost with tiered pricing
  if (context1mApplied && inputCostPerToken != null && usage.input_tokens != null) {
    segments.push(
      calculateTieredCost(
        usage.input_tokens,
        inputCostPerToken,
        CONTEXT_1M_INPUT_PREMIUM_MULTIPLIER
      )
    );
  } else if (inputAbove200k != null && inputCostPerToken != null && usage.input_tokens != null) {
    segments.push(
      calculateTieredCostWithSeparatePrices(usage.input_tokens, inputCostPerToken, inputAbove200k)
    );
  } else {
    segments.push(multiplyCost(usage.input_tokens, inputCostPerToken));
  }

  // Calculate output cost with tiered pricing
  if (context1mApplied && outputCostPerToken != null && usage.output_tokens != null) {
    segments.push(
      calculateTieredCost(
        usage.output_tokens,
        outputCostPerToken,
        CONTEXT_1M_OUTPUT_PREMIUM_MULTIPLIER
      )
    );
  } else if (outputAbove200k != null && outputCostPerToken != null && usage.output_tokens != null) {
    segments.push(
      calculateTieredCostWithSeparatePrices(
        usage.output_tokens,
        outputCostPerToken,
        outputAbove200k
      )
    );
  } else {
    segments.push(multiplyCost(usage.output_tokens, outputCostPerToken));
  }

  // Cache creation costs (5m TTL)
  const cacheCreation5mCost = priceData.cache_creation_5m_input_token_cost;
  segments.push(multiplyCost(cache5mTokens, cacheCreation5mCost));

  // Cache creation costs (1h TTL)
  const cacheCreation1hCost = priceData.cache_creation_1h_input_token_cost;
  segments.push(multiplyCost(cache1hTokens, cacheCreation1hCost));

  // Cache read costs
  const cacheReadCost = priceData.cache_read_input_token_cost;
  segments.push(multiplyCost(usage.cache_read_input_tokens, cacheReadCost));

  // Image tokens (Gemini image generation models)
  if (usage.output_image_tokens != null && usage.output_image_tokens > 0) {
    const imageCostPerToken =
      priceData.output_cost_per_image_token ?? priceData.output_cost_per_token;
    segments.push(multiplyCost(usage.output_image_tokens, imageCostPerToken));
  }

  if (usage.input_image_tokens != null && usage.input_image_tokens > 0) {
    const imageCostPerToken =
      priceData.input_cost_per_image_token ?? priceData.input_cost_per_token;
    segments.push(multiplyCost(usage.input_image_tokens, imageCostPerToken));
  }

  const total = segments.reduce((acc, segment) => acc.plus(segment), new Decimal(0));

  // Apply multiplier
  const multiplierDecimal = new Decimal(multiplier);
  return total.mul(multiplierDecimal).toDecimalPlaces(COST_SCALE);
}
```

### Token Aggregation for Session Stats

**File**: `/Users/ding/Github/claude-code-hub/src/repository/message.ts`

The `aggregateSessionStats` function aggregates token usage at the session level:

```typescript
export async function aggregateSessionStats(sessionId: string): Promise<{
  sessionId: string;
  requestCount: number;
  totalCostUsd: string;
  totalInputTokens: number;
  totalOutputTokens: number;
  totalCacheCreationTokens: number;
  totalCacheReadTokens: number;
  totalDurationMs: number;
  firstRequestAt: Date | null;
  lastRequestAt: Date | null;
  providers: Array<{ id: number; name: string }>;
  models: string[];
  userName: string;
  userId: number;
  keyName: string;
  keyId: number;
  userAgent: string | null;
  apiType: string | null;
  cacheTtlApplied: string | null;
} | null> {
  // Aggregate statistics
  const [stats] = await db
    .select({
      requestCount: sql<number>`count(*)::int`,
      totalCostUsd: sql<string>`COALESCE(sum(${messageRequest.costUsd}), '0')`,
      totalInputTokens: sql<number>`COALESCE(sum(${messageRequest.inputTokens}), 0)::int`,
      totalOutputTokens: sql<number>`COALESCE(sum(${messageRequest.outputTokens}), 0)::int`,
      totalCacheCreationTokens: sql<number>`COALESCE(sum(${messageRequest.cacheCreationInputTokens}), 0)::int`,
      totalCacheReadTokens: sql<number>`COALESCE(sum(${messageRequest.cacheReadInputTokens}), 0)::int`,
      totalDurationMs: sql<number>`COALESCE(sum(${messageRequest.durationMs}), 0)::int`,
      firstRequestAt: sql<Date>`min(${messageRequest.createdAt})`,
      lastRequestAt: sql<Date>`max(${messageRequest.createdAt})`,
    })
    .from(messageRequest)
    .where(
      and(
        eq(messageRequest.sessionId, sessionId),
        isNull(messageRequest.deletedAt)
      )
    );

  // ... additional queries for providers, models, user info

  return {
    sessionId,
    requestCount: stats.requestCount,
    totalCostUsd: stats.totalCostUsd,
    totalInputTokens: stats.totalInputTokens,
    totalOutputTokens: stats.totalOutputTokens,
    totalCacheCreationTokens: stats.totalCacheCreationTokens,
    totalCacheReadTokens: stats.totalCacheReadTokens,
    totalDurationMs: stats.totalDurationMs,
    // ... other fields
  };
}
```

### Token Formatting Utility

**File**: `/Users/ding/Github/claude-code-hub/src/lib/utils/token.ts`

```typescript
const TOKEN_UNIT_K = 1000;
const TOKEN_UNIT_M = TOKEN_UNIT_K * TOKEN_UNIT_K;

const NUMBER_FORMAT_OPTIONS: Intl.NumberFormatOptions = {
  minimumFractionDigits: 0,
  maximumFractionDigits: 2,
};

function formatNumber(value: number): string {
  return value.toLocaleString(undefined, NUMBER_FORMAT_OPTIONS);
}

function appendUnit(value: number, divisor: number, unit: string): string {
  const scaled = value / divisor;
  return `${formatNumber(scaled)}${unit}`;
}

/**
 * 统一的 Token 数值格式化函数
 * - 小于 1000 显示原值
 * - 小于 1000 * 1000 时转为 K，保留2位小数
 * - 其他情况转为 M，保留2位小数
 * - 空值返回 "-"
 */
export function formatTokenAmount(value: number | null | undefined): string {
  if (value === null || value === undefined) {
    return "-";
  }

  const absolute = Math.abs(value);

  if (absolute < TOKEN_UNIT_K) {
    return formatNumber(value);
  }

  if (absolute < TOKEN_UNIT_M) {
    return appendUnit(value, TOKEN_UNIT_K, "K");
  }

  return appendUnit(value, TOKEN_UNIT_M, "M");
}
```

### Token Usage in Rate Limiting

**File**: `/Users/ding/Github/claude-code-hub/src/lib/rate-limit/service.ts`

Token usage is tracked to Redis for real-time rate limiting:

```typescript
static async trackCost(
  keyId: number,
  providerId: number,
  _sessionId: string,
  cost: number,
  options?: {
    keyResetTime?: string;
    keyResetMode?: DailyResetMode;
    providerResetTime?: string;
    providerResetMode?: DailyResetMode;
    requestId?: number;
    createdAtMs?: number;
  }
): Promise<void> {
  if (!RateLimitService.redis || cost <= 0) return;

  const now = options?.createdAtMs ?? Date.now();
  const window5h = 5 * 60 * 60 * 1000;

  const ttl5h = Math.ceil(window5h / 1000);
  const ttlDaily = await getTTLForPeriodWithMode("daily", keyDailyReset.normalized, keyDailyMode);
  const ttlWeekly = await getTTLForPeriod("weekly");
  const ttlMonthly = await getTTLForPeriod("monthly");

  // 5h rolling window: Use Lua script (ZSET)
  await RateLimitService.redis.eval(
    TRACK_COST_5H_ROLLING_WINDOW,
    1,
    `key:${keyId}:cost_5h_rolling`,
    cost.toString(),
    now.toString(),
    window5h.toString(),
    requestId
  );

  // Daily cost tracking
  const dailyKey = mode === "rolling"
    ? `key:${keyId}:cost_daily_rolling`
    : `key:${keyId}:cost_daily_${dailyResetInfo.suffix}`;
  
  if (mode === "rolling") {
    await RateLimitService.redis.eval(
      TRACK_COST_DAILY_ROLLING_WINDOW,
      1,
      dailyKey,
      cost.toString(),
      now.toString(),
      window24h.toString(),
      requestId
    );
  } else {
    await RateLimitService.redis.incrbyfloat(dailyKey, cost);
    await RateLimitService.redis.expire(dailyKey, ttlDaily);
  }

  // Weekly and monthly tracking (similar pattern)
  // ...
}
```

### Provider Testing Token Parsing

**File**: `/Users/ding/Github/claude-code-hub/src/lib/provider-testing/parsers/anthropic-parser.ts`

```typescript
export function parseAnthropicResponse(body: string, contentType?: string): ParsedResponse {
  // Check if streaming response
  if (isSSEResponse(body, contentType)) {
    return parseSSEStream(body);
  }

  // Parse non-streaming JSON response
  try {
    const data = JSON.parse(body) as AnthropicResponse;

    // Handle error response
    if (data.error) {
      return {
        content: data.error.message || "Unknown error",
        model: undefined,
        usage: undefined,
        isStreaming: false,
      };
    }

    // Extract text content
    const textParts = data.content?.filter((c) => c.type === "text").map((c) => c.text || "") || [];
    const content = textParts.join("");

    // Extract usage
    let usage: TokenUsage | undefined;
    if (data.usage) {
      usage = {
        inputTokens: data.usage.input_tokens || 0,
        outputTokens: data.usage.output_tokens || 0,
        cacheCreationInputTokens: data.usage.cache_creation_input_tokens,
        cacheReadInputTokens: data.usage.cache_read_input_tokens,
        cacheCreation5mInputTokens: data.usage.cache_creation?.ephemeral_5m_input_tokens,
        cacheCreation1hInputTokens: data.usage.cache_creation?.ephemeral_1h_input_tokens,
      };

      if (
        usage.cacheCreationInputTokens === undefined &&
        (usage.cacheCreation5mInputTokens || usage.cacheCreation1hInputTokens)
      ) {
        usage.cacheCreationInputTokens =
          (usage.cacheCreation5mInputTokens || 0) + (usage.cacheCreation1hInputTokens || 0);
      }
    }

    return {
      content,
      model: data.model,
      usage,
      isStreaming: false,
    };
  } catch {
    // Return raw body if JSON parsing fails
    return {
      content: body.slice(0, 500),
      model: undefined,
      usage: undefined,
      isStreaming: false,
    };
  }
}
```

### Session Token Aggregation

**File**: `/Users/ding/Github/claude-code-hub/src/lib/session-manager.ts`

```typescript
static async getSessionById(sessionId: string): Promise<ActiveSessionInfo | null> {
  const redis = getRedisClient();
  if (!redis || redis.status !== "ready") return null;

  const infoKey = `session:${sessionId}:info`;
  const usageKey = `session:${sessionId}:usage`;

  const [infoData, usageData] = await Promise.all([
    redis.get(infoKey),
    redis.hgetall(usageKey),
  ]);

  if (!infoData) return null;

  const info = JSON.parse(infoData) as SessionStoreInfo;
  const session: ActiveSessionInfo = {
    sessionId,
    userName: info.userName,
    userId: info.userId,
    keyName: info.keyName,
    keyId: info.keyId,
    model: info.model,
    apiType: info.apiType,
    // Parse usage data
    inputTokens: usageData.inputTokens ? parseInt(usageData.inputTokens, 10) : 0,
    outputTokens: usageData.outputTokens ? parseInt(usageData.outputTokens, 10) : 0,
    cacheCreationInputTokens: usageData.cacheCreationInputTokens
      ? parseInt(usageData.cacheCreationInputTokens, 10)
      : 0,
    cacheReadInputTokens: usageData.cacheReadInputTokens
      ? parseInt(usageData.cacheReadInputTokens, 10)
      : 0,
    costUsd: usageData.costUsd || "0",
    requestCount: usageData.requestCount ? parseInt(usageData.requestCount, 10) : 0,
    status: (usageData.status as "completed" | "error") || "completed",
    statusCode: usageData.statusCode ? parseInt(usageData.statusCode, 10) : undefined,
  };

  // Calculate total tokens
  const input = session.inputTokens || 0;
  const output = session.outputTokens || 0;
  const cacheCreate = session.cacheCreationInputTokens || 0;
  const cacheRead = session.cacheReadInputTokens || 0;
  session.totalTokens = input + output + cacheCreate + cacheRead;

  return session;
}
```

### Usage Logs Repository

**File**: `/Users/ding/Github/claude-code-hub/src/repository/usage-logs.ts`

```typescript
export interface UsageLogRow {
  id: number;
  createdAt: Date | null;
  sessionId: string | null;
  requestSequence: number | null;
  userName: string;
  keyName: string;
  providerName: string | null;
  model: string | null;
  originalModel: string | null;
  endpoint: string | null;
  statusCode: number | null;
  inputTokens: number | null;
  outputTokens: number | null;
  cacheCreationInputTokens: number | null;
  cacheReadInputTokens: number | null;
  cacheCreation5mInputTokens: number | null;
  cacheCreation1hInputTokens: number | null;
  totalTokens: number;
  costUsd: string | null;
  durationMs: number | null;
  ttfbMs: number | null;
  errorMessage: string | null;
  providerChain: ProviderChainItem[] | null;
  blockedBy: string | null;
  blockedReason: string | null;
  userAgent: string | null;
  messagesCount: number | null;
  context1mApplied: boolean | null;
  specialSettings: SpecialSetting[] | null;
}

export interface UsageLogSummary {
  totalRequests: number;
  totalCost: number;
  totalTokens: number;
  totalInputTokens: number;
  totalOutputTokens: number;
  totalCacheCreationTokens: number;
  totalCacheReadTokens: number;
  totalCacheCreation5mTokens: number;
  totalCacheCreation1hTokens: number;
}
```

### Key Statistics with Token Aggregation

**File**: `/Users/ding/Github/claude-code-hub/src/repository/key.ts`

```typescript
const modelStatsRows = await db
  .select({
    key: messageRequest.key,
    model: messageRequest.model,
    callCount: sql<number>`count(*)::int`,
    totalCost: sum(messageRequest.costUsd),
    inputTokens: sql<number>`COALESCE(sum(${messageRequest.inputTokens}), 0)::double precision`,
    outputTokens: sql<number>`COALESCE(sum(${messageRequest.outputTokens}), 0)::double precision`,
    cacheCreationTokens: sql<number>`COALESCE(sum(${messageRequest.cacheCreationInputTokens}), 0)::double precision`,
    cacheReadTokens: sql<number>`COALESCE(sum(${messageRequest.cacheReadInputTokens}), 0)::double precision`,
  })
  .from(messageRequest)
  .where(
    and(
      inArray(messageRequest.key, keyStrings),
      isNull(messageRequest.deletedAt),
      EXCLUDE_WARMUP_CONDITION,
      gte(messageRequest.createdAt, today),
      lt(messageRequest.createdAt, tomorrow)
    )
  )
  .groupBy(messageRequest.key, messageRequest.model);
```

### Data Generator Token Statistics

**File**: `/Users/ding/Github/claude-code-hub/src/lib/data-generator/analyzer.ts`

```typescript
export interface TokenStats {
  mean: number;
  stddev: number;
}

// Calculate token statistics from historical logs
const totalTokens =
  (log.inputTokens || 0) +
  (log.outputTokens || 0) +
  (log.cacheCreationInputTokens || 0) +
  (log.cacheReadInputTokens || 0);

if (totalTokens > 0) {
  tokenValues.push(totalTokens);
}

// Calculate mean and standard deviation
const tokenStats: TokenStats = calculateMeanAndStddev(tokenValues);
```

---

## Summary

The Token Statistics system in claude-code-hub is a comprehensive solution that:

1. **Normalizes** token data from multiple providers (Claude, OpenAI, Gemini, Codex) into a unified schema
2. **Tracks** detailed token categories: input, output, cache creation (5m/1h TTL), cache read, and image tokens
3. **Stores** token data in PostgreSQL with optimized indexes for efficient querying
4. **Aggregates** tokens at session, user, key, and provider levels for analytics
5. **Calculates** costs using tiered pricing models (200K threshold, 1M context premium)
6. **Supports** real-time rate limiting through Redis-backed token tracking
7. **Handles** edge cases like provider format variations, token deductions, and missing data

The architecture ensures accurate billing, comprehensive monitoring, and fair resource allocation across all users and keys.
