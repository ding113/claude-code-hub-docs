# Token 统计 (Token Statistics) - Round 2 Verified Draft

## Intent Analysis

The Token Statistics documentation provides a comprehensive technical reference for understanding how claude-code-hub tracks, aggregates, and utilizes token usage data across the entire request lifecycle. This feature is fundamental to:

1. **Cost Calculation**: Accurate token counting is the foundation of cost calculation and billing
2. **Rate Limiting**: Token-based quotas help prevent abuse and manage resource allocation
3. **Monitoring & Analytics**: Token statistics provide insights into usage patterns and system health
4. **Multi-Provider Support**: Normalizing token data from different AI providers (Claude, OpenAI, Gemini, Codex)

The documentation serves both operators who need to understand system behavior and developers who need to integrate with or extend the token tracking system.

## Behavior Summary

### Token Types Tracked

The system tracks multiple categories of tokens to support accurate billing and analytics:

1. **Input Tokens**: Tokens sent to the model in the request (prompt)
2. **Output Tokens**: Tokens generated by the model in the response (completion)
3. **Cache Creation Tokens**: Tokens written to prompt cache (5m or 1h TTL variants)
4. **Cache Read Tokens**: Tokens read from existing prompt cache
5. **Image Tokens**: Special modality tokens for image input/output (Gemini support)

### Token Flow Overview

```
Request → Proxy Handler → Provider API → Response → Usage Extraction → 
Database Storage → Aggregation → Rate Limit Check → Cost Calculation
```

### Key Behaviors

1. **Provider-Specific Normalization**: Different providers return usage in different formats; the system normalizes all to a common schema
2. **Streaming Response Handling**: Token usage is extracted from SSE streams in real-time
3. **Dual Storage**: Token data is stored both in PostgreSQL for persistence and Redis for real-time rate limiting
4. **Async Write Buffer**: Token updates use a write buffer to optimize database performance (controlled by `MESSAGE_REQUEST_WRITE_MODE`)
5. **Session Aggregation**: Tokens are aggregated at the session level for monitoring

## Database Schema

### Message Request Table

Token statistics are stored in the `message_request` table defined in `/Users/ding/Github/claude-code-hub/src/drizzle/schema.ts`:

```typescript
// Message Request table - Token-related fields
export const messageRequest = pgTable('message_request', {
  id: serial('id').primaryKey(),
  providerId: integer('provider_id').notNull(),
  userId: integer('user_id').notNull(),
  key: varchar('key').notNull(),
  model: varchar('model', { length: 128 }),
  
  // Token usage information
  inputTokens: bigint('input_tokens', { mode: 'number' }),
  outputTokens: bigint('output_tokens', { mode: 'number' }),
  cacheCreationInputTokens: bigint('cache_creation_input_tokens', { mode: 'number' }),
  cacheReadInputTokens: bigint('cache_read_input_tokens', { mode: 'number' }),
  cacheCreation5mInputTokens: bigint('cache_creation_5m_input_tokens', { mode: 'number' }),
  cacheCreation1hInputTokens: bigint('cache_creation_1h_input_tokens', { mode: 'number' }),
  cacheTtlApplied: varchar('cache_ttl_applied', { length: 10 }),
  
  // 1M Context Window application status
  context1mApplied: boolean('context_1m_applied').default(false),
  
  createdAt: timestamp('created_at', { withTimezone: true }).defaultNow(),
  updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow(),
  deletedAt: timestamp('deleted_at', { withTimezone: true }),
}, (table) => ({
  // Optimized composite index for statistics queries (user + time + cost)
  messageRequestUserDateCostIdx: index('idx_message_request_user_date_cost')
    .on(table.userId, table.createdAt, table.costUsd)
    .where(sql`${table.deletedAt} IS NULL`),
  // Session query index (aggregate by session to view conversations)
  messageRequestSessionIdIdx: index('idx_message_request_session_id')
    .on(table.sessionId)
    .where(sql`${table.deletedAt} IS NULL`),
  // Session + Sequence composite index (for session request list queries)
  messageRequestSessionSeqIdx: index('idx_message_request_session_seq')
    .on(table.sessionId, table.requestSequence)
    .where(sql`${table.deletedAt} IS NULL`),
}));
```

**Note**: Token fields use `bigint` type (upgraded from `integer` in migration `0057_conscious_quicksilver.sql`) to handle large token counts for models with 1M+ context windows.

### UsageMetrics Type Definition

Located in `/Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts`:

```typescript
export type UsageMetrics = {
  input_tokens?: number;
  output_tokens?: number;
  cache_creation_input_tokens?: number;
  cache_creation_5m_input_tokens?: number;
  cache_creation_1h_input_tokens?: number;
  cache_ttl?: "5m" | "1h" | "mixed";
  cache_read_input_tokens?: number;
  // Image modality tokens (extracted from candidatesTokensDetails/promptTokensDetails)
  input_image_tokens?: number;
  output_image_tokens?: number;
};
```

### Environment Configuration

Token-related configuration is controlled through environment variables (defined in `/Users/ding/Github/claude-code-hub/src/lib/config/env.schema.ts`):

- `MESSAGE_REQUEST_WRITE_MODE`: Controls whether token updates use async buffer ("async") or direct writes ("sync")

## Core Token Extraction Logic

### extractUsageMetrics Function

**File**: `/Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts`

The `extractUsageMetrics` function is the central hub for normalizing token data from all providers:

```typescript
function extractUsageMetrics(value: unknown): UsageMetrics | null {
  if (!value || typeof value !== "object") {
    return null;
  }

  const usage = value as Record<string, unknown>;
  const result: UsageMetrics = {};
  let hasAny = false;

  // Standard input_tokens
  if (typeof usage.input_tokens === "number") {
    result.input_tokens = usage.input_tokens;
    hasAny = true;
  }

  // Gemini support
  // Note: promptTokenCount includes cachedContentTokenCount, must subtract to avoid double billing
  // Billing formula: input = (promptTokenCount - cachedContentTokenCount) × input_price
  //                  cache = cachedContentTokenCount × cache_price
  if (typeof usage.promptTokenCount === "number") {
    const cachedTokens =
      typeof usage.cachedContentTokenCount === "number" ? usage.cachedContentTokenCount : 0;
    result.input_tokens = Math.max(usage.promptTokenCount - cachedTokens, 0);
    hasAny = true;
  }
  if (typeof usage.candidatesTokenCount === "number") {
    result.output_tokens = usage.candidatesTokenCount;
    hasAny = true;
  }
  // Gemini cache support
  if (typeof usage.cachedContentTokenCount === "number") {
    result.cache_read_input_tokens = usage.cachedContentTokenCount;
    hasAny = true;
  }

  // Gemini modality-specific token details (IMAGE/TEXT)
  // candidatesTokensDetails: output tokens categorized by modality
  const candidatesDetails = usage.candidatesTokensDetails as
    | Array<{ modality?: string; tokenCount?: number }>
    | undefined;
  if (Array.isArray(candidatesDetails) && candidatesDetails.length > 0) {
    let imageTokens = 0;
    let textTokens = 0;
    let hasValidToken = false;
    for (const detail of candidatesDetails) {
      if (typeof detail.tokenCount === "number" && detail.tokenCount > 0) {
        hasValidToken = true;
        const modalityUpper = detail.modality?.toUpperCase();
        if (modalityUpper === "IMAGE") {
          imageTokens += detail.tokenCount;
        } else {
          textTokens += detail.tokenCount;
        }
      }
    }
    if (imageTokens > 0) {
      result.output_image_tokens = imageTokens;
      hasAny = true;
    }
    if (hasValidToken) {
      // Calculate unclassified TEXT tokens: candidatesTokenCount - sum of details
      // These may be internal overhead for image generation, billed at TEXT price
      const detailsSum = imageTokens + textTokens;
      const candidatesTotal =
        typeof usage.candidatesTokenCount === "number" ? usage.candidatesTokenCount : 0;
      const unaccountedTokens = Math.max(candidatesTotal - detailsSum, 0);
      result.output_tokens = textTokens + unaccountedTokens;
      hasAny = true;
    }
  }

  // promptTokensDetails: input tokens categorized by modality
  const promptDetails = usage.promptTokensDetails as
    | Array<{ modality?: string; tokenCount?: number }>
    | undefined;
  if (Array.isArray(promptDetails) && promptDetails.length > 0) {
    let imageTokens = 0;
    let textTokens = 0;
    let hasValidToken = false;
    for (const detail of promptDetails) {
      if (typeof detail.tokenCount === "number" && detail.tokenCount > 0) {
        hasValidToken = true;
        const modalityUpper = detail.modality?.toUpperCase();
        if (modalityUpper === "IMAGE") {
          imageTokens += detail.tokenCount;
        } else {
          textTokens += detail.tokenCount;
        }
      }
    }
    if (imageTokens > 0) {
      result.input_image_tokens = imageTokens;
      hasAny = true;
    }
    if (hasValidToken) {
      result.input_tokens = textTokens;
      hasAny = true;
    }
  }

  if (typeof usage.output_tokens === "number") {
    result.output_tokens = usage.output_tokens;
    hasAny = true;
  }

  // Gemini thinking/reasoning tokens: directly added to output_tokens (thinking price same as output price)
  // Note: placed after output_tokens assignment to avoid being overwritten
  // output_tokens exists during conversion, native Gemini interface doesn't have this value
  // Usually when output_tokens exists, thoughtsTokenCount=0
  if (typeof usage.thoughtsTokenCount === "number" && usage.thoughtsTokenCount > 0) {
    result.output_tokens = (result.output_tokens ?? 0) + usage.thoughtsTokenCount;
    hasAny = true;
  }

  if (typeof usage.cache_creation_input_tokens === "number") {
    result.cache_creation_input_tokens = usage.cache_creation_input_tokens;
    hasAny = true;
  }

  const cacheCreationDetails = usage.cache_creation as Record<string, unknown> | undefined;
  let cacheCreationDetailedTotal = 0;

  if (cacheCreationDetails) {
    if (typeof cacheCreationDetails.ephemeral_5m_input_tokens === "number") {
      result.cache_creation_5m_input_tokens = cacheCreationDetails.ephemeral_5m_input_tokens;
      cacheCreationDetailedTotal += cacheCreationDetails.ephemeral_5m_input_tokens;
      hasAny = true;
    }
    if (typeof cacheCreationDetails.ephemeral_1h_input_tokens === "number") {
      result.cache_creation_1h_input_tokens = cacheCreationDetails.ephemeral_1h_input_tokens;
      cacheCreationDetailedTotal += cacheCreationDetails.ephemeral_1h_input_tokens;
      hasAny = true;
    }
  }

  // Support top-level flat format: cache_creation_5m_input_tokens / cache_creation_1h_input_tokens
  // Some providers/relays return细分 fields directly at top level, not nested in cache_creation object
  // Priority: nested format > top-level flat format > old relay format
  if (
    result.cache_creation_5m_input_tokens === undefined &&
    typeof usage.cache_creation_5m_input_tokens === "number"
  ) {
    result.cache_creation_5m_input_tokens = usage.cache_creation_5m_input_tokens;
    cacheCreationDetailedTotal += usage.cache_creation_5m_input_tokens;
    hasAny = true;
  }
  if (
    result.cache_creation_1h_input_tokens === undefined &&
    typeof usage.cache_creation_1h_input_tokens === "number"
  ) {
    result.cache_creation_1h_input_tokens = usage.cache_creation_1h_input_tokens;
    cacheCreationDetailedTotal += usage.cache_creation_1h_input_tokens;
    hasAny = true;
  }

  // Support some relay / old field naming: claude_cache_creation_5_m_tokens / claude_cache_creation_1_h_tokens
  // Only used when standard fields are missing, to avoid duplicate counting (lowest priority)
  if (
    result.cache_creation_5m_input_tokens === undefined &&
    typeof usage.claude_cache_creation_5_m_tokens === "number"
  ) {
    result.cache_creation_5m_input_tokens = usage.claude_cache_creation_5_m_tokens;
    cacheCreationDetailedTotal += usage.claude_cache_creation_5_m_tokens;
    hasAny = true;
  }
  if (
    result.cache_creation_1h_input_tokens === undefined &&
    typeof usage.claude_cache_creation_1_h_tokens === "number"
  ) {
    result.cache_creation_1h_input_tokens = usage.claude_cache_creation_1_h_tokens;
    cacheCreationDetailedTotal += usage.claude_cache_creation_1_h_tokens;
    hasAny = true;
  }

  if (result.cache_creation_input_tokens === undefined && cacheCreationDetailedTotal > 0) {
    result.cache_creation_input_tokens = cacheCreationDetailedTotal;
  }

  if (!result.cache_ttl) {
    if (result.cache_creation_1h_input_tokens && result.cache_creation_5m_input_tokens) {
      result.cache_ttl = "mixed";
    } else if (result.cache_creation_1h_input_tokens) {
      result.cache_ttl = "1h";
    } else if (result.cache_creation_5m_input_tokens) {
      result.cache_ttl = "5m";
    }
  }

  // Claude format: top-level cache_read_input_tokens (flat structure)
  if (typeof usage.cache_read_input_tokens === "number") {
    result.cache_read_input_tokens = usage.cache_read_input_tokens;
    hasAny = true;
  }

  // OpenAI Response API format: input_tokens_details.cached_tokens (nested structure)
  // Only used when top-level field doesn't exist (to avoid double counting)
  if (!result.cache_read_input_tokens) {
    const inputTokensDetails = usage.input_tokens_details as Record<string, unknown> | undefined;
    if (inputTokensDetails && typeof inputTokensDetails.cached_tokens === "number") {
      result.cache_read_input_tokens = inputTokensDetails.cached_tokens;
      hasAny = true;
    }
  }

  return hasAny ? result : null;
}
```

### parseUsageFromResponseText Function

**File**: `/Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts`

The `parseUsageFromResponseText` function handles both streaming and non-streaming responses:

```typescript
export function parseUsageFromResponseText(
  responseText: string,
  providerType: string | null | undefined
): {
  usageRecord: Record<string, unknown> | null;
  usageMetrics: UsageMetrics | null;
} {
  let usageRecord: Record<string, unknown> | null = null;
  let usageMetrics: UsageMetrics | null = null;

  const applyUsageValue = (value: unknown, source: string) => {
    if (usageMetrics) {
      return;
    }

    if (!value || typeof value !== "object") {
      return;
    }

    const extracted = extractUsageMetrics(value);
    if (!extracted) {
      return;
    }

    usageRecord = value as Record<string, unknown>;
    usageMetrics = adjustUsageForProviderType(extracted, providerType);

    logger.debug("[ResponseHandler] Parsed usage from response", {
      source,
      providerType,
      usage: usageMetrics,
    });
  };

  try {
    const parsedValue = JSON.parse(responseText);

    if (parsedValue && typeof parsedValue === "object" && !Array.isArray(parsedValue)) {
      const parsed = parsedValue as Record<string, unknown>;

      // Standard usage fields
      applyUsageValue(parsed.usage, "json.root.usage");

      // Gemini usageMetadata (direct)
      applyUsageValue(parsed.usageMetadata, "json.root.usageMetadata");

      // Handle response wrapping (some Gemini providers return {response: {...}})
      if (parsed.response && typeof parsed.response === "object") {
        const responseObj = parsed.response as Record<string, unknown>;
        applyUsageValue(responseObj.usage, "json.response.usage");
        applyUsageValue(responseObj.usageMetadata, "json.response.usageMetadata");
      }

      if (Array.isArray(parsed.output)) {
        for (const item of parsed.output as Array<Record<string, unknown>>) {
          if (!item || typeof item !== "object") {
            continue;
          }
          applyUsageValue(item.usage, "json.output");
        }
      }
    }

    if (!usageMetrics && Array.isArray(parsedValue)) {
      for (const item of parsedValue) {
        if (!item || typeof item !== "object") {
          continue;
        }

        const record = item as Record<string, unknown>;
        applyUsageValue(record.usage, "json.array");

        if (record.data && typeof record.data === "object") {
          applyUsageValue((record.data as Record<string, unknown>).usage, "json.array.data");
        }
      }
    }
  } catch {
    // Fallback to SSE parsing when body is not valid JSON
  }

  // SSE parsing: supports two formats
  // 1. Standard SSE (event: + data:) - Claude/OpenAI
  // 2. Pure data: format - Gemini
  if (!usageMetrics && responseText.includes("data:")) {
    const events = parseSSEData(responseText);

    // Claude SSE special handling:
    // - message_delta usually contains more complete usage (should be preferred)
    // - message_start may contain cache_creation TTL细分 fields (as supplement for missing fields)
    let messageStartUsage: UsageMetrics | null = null;
    let messageDeltaUsage: UsageMetrics | null = null;

    const mergeUsageMetrics = (base: UsageMetrics | null, patch: UsageMetrics): UsageMetrics => {
      if (!base) {
        return { ...patch };
      }

      return {
        input_tokens: patch.input_tokens ?? base.input_tokens,
        output_tokens: patch.output_tokens ?? base.output_tokens,
        cache_creation_input_tokens:
          patch.cache_creation_input_tokens ?? base.cache_creation_input_tokens,
        cache_creation_5m_input_tokens:
          patch.cache_creation_5m_input_tokens ?? base.cache_creation_5m_input_tokens,
        cache_creation_1h_input_tokens:
          patch.cache_creation_1h_input_tokens ?? base.cache_creation_1h_input_tokens,
        cache_ttl: patch.cache_ttl ?? base.cache_ttl,
        cache_read_input_tokens: patch.cache_read_input_tokens ?? base.cache_read_input_tokens,
      };
    };

    for (const event of events) {
      // ... event processing logic
    }

    // Claude SSE merge rule: prefer message_delta, fallback to message_start for missing fields
    const mergedClaudeUsage = (() => {
      if (messageDeltaUsage && messageStartUsage) {
        return mergeUsageMetrics(messageStartUsage, messageDeltaUsage);
      }
      return messageDeltaUsage ?? messageStartUsage;
    })();

    if (mergedClaudeUsage) {
      usageMetrics = adjustUsageForProviderType(mergedClaudeUsage, providerType);
      usageRecord = mergedClaudeUsage as unknown as Record<string, unknown>;
    }
  }

  return { usageRecord, usageMetrics };
}
```

## Provider-Specific Token Adjustments

### Codex Cache Token Adjustment

**File**: `/Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts`

Codex includes cached tokens in input_tokens, requiring adjustment:

```typescript
function adjustUsageForProviderType(
  usage: UsageMetrics,
  providerType: string | null | undefined
): UsageMetrics {
  if (providerType !== "codex") {
    return usage;
  }

  const cachedTokens = usage.cache_read_input_tokens;
  const inputTokens = usage.input_tokens;

  if (typeof cachedTokens !== "number" || typeof inputTokens !== "number") {
    return usage;
  }

  const adjustedInput = Math.max(inputTokens - cachedTokens, 0);
  if (adjustedInput === inputTokens) {
    return usage;
  }

  logger.debug("[UsageMetrics] Adjusted codex input tokens to exclude cached tokens", {
    providerType,
    originalInputTokens: inputTokens,
    cachedTokens,
    adjustedInputTokens: adjustedInput,
  });

  return {
    ...usage,
    input_tokens: adjustedInput,
  };
}
```

## Cost Calculation

**File**: `/Users/ding/Github/claude-code-hub/src/lib/utils/cost-calculation.ts`

The cost calculation function handles tiered pricing for different token types:

```typescript
export function calculateRequestCost(
  usage: UsageMetrics,
  priceData: ModelPriceData,
  multiplier: number = 1.0,
  context1mApplied: boolean = false
): Decimal {
  const segments: Decimal[] = [];

  const inputCostPerToken = priceData.input_cost_per_token;
  const outputCostPerToken = priceData.output_cost_per_token;
  const inputCostPerRequest = priceData.input_cost_per_request;

  // Per-request fixed fee (added to token fees)
  if (
    typeof inputCostPerRequest === "number" &&
    Number.isFinite(inputCostPerRequest) &&
    inputCostPerRequest >= 0
  ) {
    const requestCost = toDecimal(inputCostPerRequest);
    if (requestCost) {
      segments.push(requestCost);
    }
  }

  // Derive cache creation costs with fallback logic
  const cacheCreation5mCost =
    priceData.cache_creation_input_token_cost ??
    (inputCostPerToken != null ? inputCostPerToken * 1.25 : undefined);

  const cacheCreation1hCost =
    priceData.cache_creation_input_token_cost_above_1hr ??
    (inputCostPerToken != null ? inputCostPerToken * 2 : undefined) ??
    cacheCreation5mCost;

  const cacheReadCost =
    priceData.cache_read_input_token_cost ??
    (inputCostPerToken != null
      ? inputCostPerToken * 0.1
      : outputCostPerToken != null
        ? outputCostPerToken * 0.1
        : undefined);

  // Derive cache creation tokens by TTL
  let cache5mTokens = usage.cache_creation_5m_input_tokens;
  let cache1hTokens = usage.cache_creation_1h_input_tokens;

  if (typeof usage.cache_creation_input_tokens === "number") {
    const remaining =
      usage.cache_creation_input_tokens - (cache5mTokens ?? 0) - (cache1hTokens ?? 0);

    if (remaining > 0) {
      const target = usage.cache_ttl === "1h" ? "1h" : "5m";
      if (target === "1h") {
        cache1hTokens = (cache1hTokens ?? 0) + remaining;
      } else {
        cache5mTokens = (cache5mTokens ?? 0) + remaining;
      }
    }
  }

  // Check for 200K tiered pricing (Gemini models)
  const inputAbove200k = priceData.input_cost_per_token_above_200k_tokens;
  const outputAbove200k = priceData.output_cost_per_token_above_200k_tokens;

  // Calculate input cost with tiered pricing
  // Priority: context1mApplied > 200K tier > normal
  if (context1mApplied && inputCostPerToken != null && usage.input_tokens != null) {
    // Claude 1M context: use multiplier calculation
    segments.push(
      calculateTieredCost(
        usage.input_tokens,
        inputCostPerToken,
        CONTEXT_1M_INPUT_PREMIUM_MULTIPLIER
      )
    );
  } else if (inputAbove200k != null && inputCostPerToken != null && usage.input_tokens != null) {
    // Gemini etc: use separate price fields
    segments.push(
      calculateTieredCostWithSeparatePrices(usage.input_tokens, inputCostPerToken, inputAbove200k)
    );
  } else {
    // Normal calculation
    segments.push(multiplyCost(usage.input_tokens, inputCostPerToken));
  }

  // Calculate output cost with tiered pricing
  if (context1mApplied && outputCostPerToken != null && usage.output_tokens != null) {
    // Claude 1M context: use multiplier calculation
    segments.push(
      calculateTieredCost(
        usage.output_tokens,
        outputCostPerToken,
        CONTEXT_1M_OUTPUT_PREMIUM_MULTIPLIER
      )
    );
  } else if (outputAbove200k != null && outputCostPerToken != null && usage.output_tokens != null) {
    // Gemini etc: use separate price fields
    segments.push(
      calculateTieredCostWithSeparatePrices(
        usage.output_tokens,
        outputCostPerToken,
        outputAbove200k
      )
    );
  } else {
    // Normal calculation
    segments.push(multiplyCost(usage.output_tokens, outputCostPerToken));
  }

  // Cache creation costs (5m TTL)
  // Priority: context1mApplied > 200K tier > normal
  if (context1mApplied && cacheCreation5mCost != null && cache5mTokens != null) {
    segments.push(
      calculateTieredCost(cache5mTokens, cacheCreation5mCost, CONTEXT_1M_INPUT_PREMIUM_MULTIPLIER)
    );
  } else {
    segments.push(multiplyCost(cache5mTokens, cacheCreation5mCost));
  }

  // Cache creation costs (1h TTL)
  if (context1mApplied && cacheCreation1hCost != null && cache1hTokens != null) {
    segments.push(
      calculateTieredCost(cache1hTokens, cacheCreation1hCost, CONTEXT_1M_INPUT_PREMIUM_MULTIPLIER)
    );
  } else {
    segments.push(multiplyCost(cache1hTokens, cacheCreation1hCost));
  }

  // Cache read costs
  segments.push(multiplyCost(usage.cache_read_input_tokens, cacheReadCost));

  // Image tokens (Gemini image generation models)
  // Output image tokens: prefer output_cost_per_image_token, fallback to output_cost_per_token
  if (usage.output_image_tokens != null && usage.output_image_tokens > 0) {
    const imageCostPerToken =
      priceData.output_cost_per_image_token ?? priceData.output_cost_per_token;
    segments.push(multiplyCost(usage.output_image_tokens, imageCostPerToken));
  }

  // Input image tokens: prefer input_cost_per_image_token, fallback to input_cost_per_token
  if (usage.input_image_tokens != null && usage.input_image_tokens > 0) {
    const imageCostPerToken =
      priceData.input_cost_per_image_token ?? priceData.input_cost_per_token;
    segments.push(multiplyCost(usage.input_image_tokens, imageCostPerToken));
  }

  const total = segments.reduce((acc, segment) => acc.plus(segment), new Decimal(0));

  // Apply multiplier
  const multiplierDecimal = new Decimal(multiplier);
  return total.mul(multiplierDecimal).toDecimalPlaces(COST_SCALE);
}
```

### 1M Context Window Tiered Pricing

**File**: `/Users/ding/Github/claude-code-hub/src/lib/special-attributes/index.ts`

```typescript
/**
 * Token threshold for tiered pricing (200k tokens)
 */
export const CONTEXT_1M_TOKEN_THRESHOLD = 200000;

/**
 * Pricing multipliers for tokens exceeding the threshold
 * - Input: 2x ($3/MTok -> $6/MTok for tokens >200k)
 * - Output: 1.5x ($15/MTok -> $22.50/MTok for tokens >200k)
 */
export const CONTEXT_1M_INPUT_PREMIUM_MULTIPLIER = 2.0;
export const CONTEXT_1M_OUTPUT_PREMIUM_MULTIPLIER = 1.5;
```

## Token Aggregation for Session Stats

**File**: `/Users/ding/Github/claude-code-hub/src/repository/message.ts`

The `aggregateSessionStats` function aggregates token usage at the session level:

```typescript
export async function aggregateSessionStats(sessionId: string): Promise<{
  sessionId: string;
  requestCount: number;
  totalCostUsd: string;
  totalInputTokens: number;
  totalOutputTokens: number;
  totalCacheCreationTokens: number;
  totalCacheReadTokens: number;
  totalDurationMs: number;
  firstRequestAt: Date | null;
  lastRequestAt: Date | null;
  providers: Array<{ id: number; name: string }>;
  models: string[];
  userName: string;
  userId: number;
  keyName: string;
  keyId: number;
  userAgent: string | null;
  apiType: string | null;
  cacheTtlApplied: string | null;
} | null> {
  // 1. Aggregate statistics
  const [stats] = await db
    .select({
      // Session existence: include all requests (including warmup)
      totalCount: sql<number>`count(*)::double precision`,
      // Session statistics: exclude warmup (not counted in any stats)
      requestCount: sql<number>`count(*) FILTER (WHERE ${EXCLUDE_WARMUP_CONDITION})::double precision`,
      totalCostUsd: sql<string>`COALESCE(sum(${messageRequest.costUsd}) FILTER (WHERE ${EXCLUDE_WARMUP_CONDITION}), 0)`,
      totalInputTokens: sql<number>`COALESCE(sum(${messageRequest.inputTokens}) FILTER (WHERE ${EXCLUDE_WARMUP_CONDITION})::double precision, 0::double precision)`,
      totalOutputTokens: sql<number>`COALESCE(sum(${messageRequest.outputTokens}) FILTER (WHERE ${EXCLUDE_WARMUP_CONDITION})::double precision, 0::double precision)`,
      totalCacheCreationTokens: sql<number>`COALESCE(sum(${messageRequest.cacheCreationInputTokens}) FILTER (WHERE ${EXCLUDE_WARMUP_CONDITION})::double precision, 0::double precision)`,
      totalCacheReadTokens: sql<number>`COALESCE(sum(${messageRequest.cacheReadInputTokens}) FILTER (WHERE ${EXCLUDE_WARMUP_CONDITION})::double precision, 0::double precision)`,
      totalDurationMs: sql<number>`COALESCE(sum(${messageRequest.durationMs}) FILTER (WHERE ${EXCLUDE_WARMUP_CONDITION})::double precision, 0::double precision)`,
      firstRequestAt: sql<Date>`min(${messageRequest.createdAt}) FILTER (WHERE ${EXCLUDE_WARMUP_CONDITION})`,
      lastRequestAt: sql<Date>`max(${messageRequest.createdAt}) FILTER (WHERE ${EXCLUDE_WARMUP_CONDITION})`,
    })
    .from(messageRequest)
    .where(and(eq(messageRequest.sessionId, sessionId), isNull(messageRequest.deletedAt)));

  // ... additional queries for providers, models, user info

  return {
    sessionId,
    requestCount: stats.requestCount,
    totalCostUsd: stats.totalCostUsd,
    totalInputTokens: stats.totalInputTokens,
    totalOutputTokens: stats.totalOutputTokens,
    totalCacheCreationTokens: stats.totalCacheCreationTokens,
    totalCacheReadTokens: stats.totalCacheReadTokens,
    totalDurationMs: stats.totalDurationMs,
    // ... other fields
  };
}
```

**Note**: The aggregation uses `EXCLUDE_WARMUP_CONDITION` to filter out warmup requests from statistics.

## Token Formatting Utility

**File**: `/Users/ding/Github/claude-code-hub/src/lib/utils/token.ts`

```typescript
const TOKEN_UNIT_K = 1000;
const TOKEN_UNIT_M = TOKEN_UNIT_K * TOKEN_UNIT_K;

const NUMBER_FORMAT_OPTIONS: Intl.NumberFormatOptions = {
  minimumFractionDigits: 0,
  maximumFractionDigits: 2,
};

function formatNumber(value: number): string {
  return value.toLocaleString(undefined, NUMBER_FORMAT_OPTIONS);
}

function appendUnit(value: number, divisor: number, unit: string): string {
  const scaled = value / divisor;
  return `${formatNumber(scaled)}${unit}`;
}

/**
 * Unified token amount formatting function
 * - Display raw value when less than 1000
 * - Convert to K with 2 decimal places when less than 1000 * 1000
 * - Convert to M with 2 decimal places otherwise
 * - Return "-" for null values
 */
export function formatTokenAmount(value: number | null | undefined): string {
  if (value === null || value === undefined) {
    return "-";
  }

  const absolute = Math.abs(value);

  if (absolute < TOKEN_UNIT_K) {
    return formatNumber(value);
  }

  if (absolute < TOKEN_UNIT_M) {
    return appendUnit(value, TOKEN_UNIT_K, "K");
  }

  return appendUnit(value, TOKEN_UNIT_M, "M");
}
```

## Token Usage in Rate Limiting

**File**: `/Users/ding/Github/claude-code-hub/src/lib/rate-limit/service.ts`

Token usage is tracked to Redis for real-time rate limiting:

```typescript
/**
 * Accumulate cost (called after request completion)
 * 5h uses rolling window (ZSET), daily uses rolling/fixed window based on mode, weekly/monthly use fixed window (STRING)
 */
static async trackCost(
  keyId: number,
  providerId: number,
  _sessionId: string,
  cost: number,
  options?: {
    keyResetTime?: string;
    keyResetMode?: DailyResetMode;
    providerResetTime?: string;
    providerResetMode?: DailyResetMode;
    requestId?: number;
    createdAtMs?: number;
  }
): Promise<void> {
  if (!RateLimitService.redis || cost <= 0) return;

  try {
    const keyDailyReset = RateLimitService.resolveDailyReset(options?.keyResetTime);
    const providerDailyReset = RateLimitService.resolveDailyReset(options?.providerResetTime);
    const keyDailyMode = options?.keyResetMode ?? "fixed";
    const providerDailyMode = options?.providerResetMode ?? "fixed";
    const now = options?.createdAtMs ?? Date.now();
    const requestId = options?.requestId != null ? String(options.requestId) : "";
    const window5h = 5 * 60 * 60 * 1000; // 5 hours in ms
    const window24h = 24 * 60 * 60 * 1000; // 24 hours in ms

    // Calculate dynamic TTL (daily/weekly/monthly)
    const ttlDailyKey = await getTTLForPeriodWithMode(
      "daily",
      keyDailyReset.normalized,
      keyDailyMode
    );
    // ... more TTL calculations

    // 1. 5h rolling window: use Lua script (ZSET)
    // Key's 5h rolling window
    await RateLimitService.redis.eval(
      TRACK_COST_5H_ROLLING_WINDOW,
      1, // KEYS count
      `key:${keyId}:cost_5h_rolling`, // KEYS[1]
      cost.toString(), // ARGV[1]: cost
      now.toString(), // ARGV[2]: now
      window5h.toString(), // ARGV[3]: window
      requestId // ARGV[4]: request_id (optional)
    );

    // Provider's 5h rolling window
    await RateLimitService.redis.eval(
      TRACK_COST_5H_ROLLING_WINDOW,
      1,
      `provider:${providerId}:cost_5h_rolling`,
      cost.toString(),
      now.toString(),
      window5h.toString(),
      requestId
    );

    // 2. daily rolling window: use Lua script (ZSET)
    if (keyDailyMode === "rolling") {
      await RateLimitService.redis.eval(
        TRACK_COST_DAILY_ROLLING_WINDOW,
        1,
        `key:${keyId}:cost_daily_rolling`,
        cost.toString(),
        now.toString(),
        window24h.toString(),
        requestId
      );
    }

    // 3. daily fixed/weekly/monthly fixed window: use STRING + dynamic TTL
    const pipeline = RateLimitService.redis.pipeline();

    // Key's daily fixed/weekly/monthly cost
    if (keyDailyMode === "fixed") {
      const keyDailyKey = `key:${keyId}:cost_daily_${keyDailyReset.suffix}`;
      pipeline.incrbyfloat(keyDailyKey, cost);
      pipeline.expire(keyDailyKey, ttlDailyKey);
    }

    pipeline.incrbyfloat(`key:${keyId}:cost_weekly`, cost);
    pipeline.expire(`key:${keyId}:cost_weekly`, ttlWeekly);

    pipeline.incrbyfloat(`key:${keyId}:cost_monthly`, cost);
    pipeline.expire(`key:${keyId}:cost_monthly`, ttlMonthly);

    // ... provider tracking

    await pipeline.exec();
  } catch (error) {
    logger.error("[RateLimit] Track cost failed:", error);
    // Silently fail
  }
}
```

## Usage Logs Repository

**File**: `/Users/ding/Github/claude-code-hub/src/repository/usage-logs.ts`

```typescript
export interface UsageLogRow {
  id: number;
  createdAt: Date | null;
  sessionId: string | null;
  requestSequence: number | null;
  userName: string;
  keyName: string;
  providerName: string | null;
  model: string | null;
  originalModel: string | null;
  endpoint: string | null;
  statusCode: number | null;
  inputTokens: number | null;
  outputTokens: number | null;
  cacheCreationInputTokens: number | null;
  cacheReadInputTokens: number | null;
  cacheCreation5mInputTokens: number | null;
  cacheCreation1hInputTokens: number | null;
  cacheTtlApplied: string | null;
  totalTokens: number;
  costUsd: string | null;
  costMultiplier: string | null;
  durationMs: number | null;
  ttfbMs: number | null;
  errorMessage: string | null;
  providerChain: ProviderChainItem[] | null;
  blockedBy: string | null;
  blockedReason: string | null;
  userAgent: string | null;
  messagesCount: number | null;
  context1mApplied: boolean | null;
  specialSettings: SpecialSetting[] | null;
}

export interface UsageLogSummary {
  totalRequests: number;
  totalCost: number;
  totalTokens: number;
  totalInputTokens: number;
  totalOutputTokens: number;
  totalCacheCreationTokens: number;
  totalCacheReadTokens: number;
  totalCacheCreation5mTokens: number;
  totalCacheCreation1hTokens: number;
}
```

## Session Token Aggregation in Redis

**File**: `/Users/ding/Github/claude-code-hub/src/lib/session-manager.ts`

```typescript
static async getSessionById(sessionId: string): Promise<ActiveSessionInfo | null> {
  const redis = getRedisClient();
  if (!redis || redis.status !== "ready") return null;

  const infoKey = `session:${sessionId}:info`;
  const usageKey = `session:${sessionId}:usage`;

  const [infoData, usageData] = await Promise.all([
    redis.get(infoKey),
    redis.hgetall(usageKey),
  ]);

  if (!infoData) return null;

  const info = JSON.parse(infoData) as SessionStoreInfo;
  const session: ActiveSessionInfo = {
    sessionId,
    userName: info.userName,
    userId: info.userId,
    keyName: info.keyName,
    keyId: info.keyId,
    model: info.model,
    apiType: info.apiType,
    // Parse usage data
    inputTokens: usageData.inputTokens ? parseInt(usageData.inputTokens, 10) : 0,
    outputTokens: usageData.outputTokens ? parseInt(usageData.outputTokens, 10) : 0,
    cacheCreationInputTokens: usageData.cacheCreationInputTokens
      ? parseInt(usageData.cacheCreationInputTokens, 10)
      : 0,
    cacheReadInputTokens: usageData.cacheReadInputTokens
      ? parseInt(usageData.cacheReadInputTokens, 10)
      : 0,
    costUsd: usageData.costUsd || "0",
    requestCount: usageData.requestCount ? parseInt(usageData.requestCount, 10) : 0,
    status: (usageData.status as "completed" | "error") || "completed",
    statusCode: usageData.statusCode ? parseInt(usageData.statusCode, 10) : undefined,
  };

  // Calculate total tokens
  const input = session.inputTokens || 0;
  const output = session.outputTokens || 0;
  const cacheCreate = session.cacheCreationInputTokens || 0;
  const cacheRead = session.cacheReadInputTokens || 0;
  session.totalTokens = input + output + cacheCreate + cacheRead;

  return session;
}
```

## Edge Cases

### 1. Provider Format Variations

Different providers return token usage in different formats. The system handles these variations in the `extractUsageMetrics` function:

**Claude Format**:
```json
{
  "usage": {
    "input_tokens": 1000,
    "output_tokens": 500,
    "cache_creation_input_tokens": 200,
    "cache_read_input_tokens": 100
  }
}
```

**OpenAI Format**:
```json
{
  "usage": {
    "prompt_tokens": 1000,
    "completion_tokens": 500,
    "input_tokens_details": {
      "cached_tokens": 100
    }
  }
}
```

**Gemini Format**:
```json
{
  "usageMetadata": {
    "promptTokenCount": 1000,
    "candidatesTokenCount": 500,
    "cachedContentTokenCount": 100
  }
}
```

### 2. Gemini Token Deduction

Gemini's `promptTokenCount` includes cached tokens, which would cause double-counting. The system automatically deducts cached tokens:

```typescript
if (typeof usage.promptTokenCount === "number") {
  const cachedTokens =
    typeof usage.cachedContentTokenCount === "number" ? usage.cachedContentTokenCount : 0;
  result.input_tokens = Math.max(usage.promptTokenCount - cachedTokens, 0);
  hasAny = true;
}
```

### 3. Cache TTL Derivation

When providers don't explicitly specify cache TTL, the system derives it from available data:

```typescript
// Derive cache creation tokens by TTL
let cache5mTokens = usage.cache_creation_5m_input_tokens;
let cache1hTokens = usage.cache_creation_1h_input_tokens;

if (typeof usage.cache_creation_input_tokens === "number") {
  const remaining =
    usage.cache_creation_input_tokens - (cache5mTokens ?? 0) - (cache1hTokens ?? 0);

  if (remaining > 0) {
    const target = usage.cache_ttl === "1h" ? "1h" : "5m";
    if (target === "1h") {
      cache1hTokens = (cache1hTokens ?? 0) + remaining;
    } else {
      cache5mTokens = (cache5mTokens ?? 0) + remaining;
    }
  }
}
```

### 4. Missing Token Data

When providers don't return usage data (e.g., during errors or certain streaming scenarios), the system gracefully handles missing data by:
- Returning `null` from `extractUsageMetrics`
- Skipping cost calculation
- Still recording the request for analytics

### 5. Token Counting Endpoint

The `/v1/messages/count_tokens` endpoint is special-cased to skip rate limiting and concurrent session tracking:

```typescript
// From /Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/session.ts
isCountTokensRequest(): boolean {
  const endpoint = this.getEndpoint();
  return endpoint === "/v1/messages/count_tokens";
}
```

Used in proxy-handler.ts:
```typescript
// Decide request type and build configured guard pipeline
const type = session.isCountTokensRequest() ? RequestType.COUNT_TOKENS : RequestType.CHAT;
const pipeline = GuardPipelineBuilder.fromRequestType(type);

// Skip concurrent count increment for count_tokens
if (session.sessionId && !session.isCountTokensRequest()) {
  await SessionTracker.incrementConcurrentCount(sessionId);
}
```

### 6. Warmup Request Exclusion

Warmup requests are excluded from token statistics:

```typescript
// EXCLUDE_WARMUP_CONDITION is used in aggregation queries
const EXCLUDE_WARMUP_CONDITION = sql`${messageRequest.blockedBy} IS NULL OR ${messageRequest.blockedBy} <> 'warmup'`;
```

## Provider Testing Token Parsing

**File**: `/Users/ding/Github/claude-code-hub/src/lib/provider-testing/parsers/anthropic-parser.ts`

```typescript
export function parseAnthropicResponse(body: string, contentType?: string): ParsedResponse {
  // Check if streaming response
  if (isSSEResponse(body, contentType)) {
    return parseSSEStream(body);
  }

  // Parse non-streaming JSON response
  try {
    const data = JSON.parse(body) as AnthropicResponse;

    // Handle error response
    if (data.error) {
      return {
        content: data.error.message || "Unknown error",
        model: undefined,
        usage: undefined,
        isStreaming: false,
      };
    }

    // Extract text content
    const textParts = data.content?.filter((c) => c.type === "text").map((c) => c.text || "") || [];
    const content = textParts.join("");

    // Extract usage
    let usage: TokenUsage | undefined;
    if (data.usage) {
      usage = {
        inputTokens: data.usage.input_tokens || 0,
        outputTokens: data.usage.output_tokens || 0,
        cacheCreationInputTokens: data.usage.cache_creation_input_tokens,
        cacheReadInputTokens: data.usage.cache_read_input_tokens,
        cacheCreation5mInputTokens: data.usage.cache_creation?.ephemeral_5m_input_tokens,
        cacheCreation1hInputTokens: data.usage.cache_creation?.ephemeral_1h_input_tokens,
      };

      if (
        usage.cacheCreationInputTokens === undefined &&
        (usage.cacheCreation5mInputTokens || usage.cacheCreation1hInputTokens)
      ) {
        usage.cacheCreationInputTokens =
          (usage.cacheCreation5mInputTokens || 0) + (usage.cacheCreation1hInputTokens || 0);
      }
    }

    return {
      content,
      model: data.model,
      usage,
      isStreaming: false,
    };
  } catch {
    // Return raw body if JSON parsing fails
    return {
      content: body.slice(0, 500),
      model: undefined,
      usage: undefined,
      isStreaming: false,
    };
  }
}
```

## Model Price Data Structure

**File**: `/Users/ding/Github/claude-code-hub/src/types/model-price.ts`

```typescript
export interface ModelPriceData {
  // Basic price information
  input_cost_per_token?: number;
  output_cost_per_token?: number;
  input_cost_per_request?: number; // Fixed fee per call (added to token fees)

  // Cache-related prices
  cache_creation_input_token_cost?: number;
  cache_creation_input_token_cost_above_1hr?: number;
  cache_read_input_token_cost?: number;

  // 200K tiered pricing (used by Gemini models)
  input_cost_per_token_above_200k_tokens?: number;
  output_cost_per_token_above_200k_tokens?: number;
  cache_creation_input_token_cost_above_200k_tokens?: number;
  cache_read_input_token_cost_above_200k_tokens?: number;

  // Image generation prices
  output_cost_per_image?: number;
  // Image token prices (per token, for Gemini image output)
  output_cost_per_image_token?: number;
  // Image input prices (per image)
  input_cost_per_image?: number;
  // Image input token prices (per token)
  input_cost_per_image_token?: number;

  // Model capability information
  supports_prompt_caching?: boolean;
  // ... other capability flags
}
```

## Summary

The Token Statistics system in claude-code-hub is a comprehensive solution that:

1. **Normalizes** token data from multiple providers (Claude, OpenAI, Gemini, Codex) into a unified schema
2. **Tracks** detailed token categories: input, output, cache creation (5m/1h TTL), cache read, and image tokens
3. **Stores** token data in PostgreSQL with optimized indexes for efficient querying
4. **Aggregates** tokens at the session, user, key, and provider levels for analytics
5. **Calculates** costs using tiered pricing models (200K threshold, 1M context premium)
6. **Supports** real-time rate limiting through Redis-backed cost tracking
7. **Handles** edge cases like provider format variations, token deductions, and missing data
8. **Excludes** warmup requests from statistics to ensure accurate billing
9. **Supports** async write buffering for high-throughput scenarios

The architecture ensures accurate billing, comprehensive monitoring, and fair resource allocation across all users and keys.

## Verified File References

| File | Description |
|------|-------------|
| `/Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/response-handler.ts` | Core token extraction and parsing logic |
| `/Users/ding/Github/claude-code-hub/src/lib/utils/cost-calculation.ts` | Cost calculation with tiered pricing |
| `/Users/ding/Github/claude-code-hub/src/lib/utils/token.ts` | Token formatting utilities |
| `/Users/ding/Github/claude-code-hub/src/drizzle/schema.ts` | Database schema definition |
| `/Users/ding/Github/claude-code-hub/src/repository/message.ts` | Message request repository with aggregation |
| `/Users/ding/Github/claude-code-hub/src/repository/usage-logs.ts` | Usage logs repository interface |
| `/Users/ding/Github/claude-code-hub/src/lib/rate-limit/service.ts` | Rate limiting with cost tracking |
| `/Users/ding/Github/claude-code-hub/src/lib/session-manager.ts` | Session management with token aggregation |
| `/Users/ding/Github/claude-code-hub/src/lib/special-attributes/index.ts` | 1M context window constants |
| `/Users/ding/Github/claude-code-hub/src/types/model-price.ts` | Model price data structure |
| `/Users/ding/Github/claude-code-hub/src/app/v1/_lib/proxy/session.ts` | Proxy session with count_tokens detection |
| `/Users/ding/Github/claude-code-hub/src/lib/provider-testing/parsers/anthropic-parser.ts` | Provider testing token parsing |
